# lp-ci-test
In our code, we allow the optimization of the hyperparameters involved in the Regularized Least-Squares estimators. To do so, we propose a Gaussian Process (GP) regression that maximizes the likelihood of the observations. While carrying out a precise GP regression can be prohibitive, in practice, we run this method only on a batch of size 200 observations randomly selected and we perform only 15 iterations for choosing the hyperparameters involved in the RLS problems. We consider the implementation of the GP proposed in [scikit-learn](https://github.com/scikit-learn/scikit-learn) where we constraint the maximum number of iterations of the GP. More precisely, in the file sklearn/gaussian_process/_gpr.py we have modified the function called "_constrained_optimization" by adding the following options to the optimizer: 
options={'disp': None, 'maxcor': 10, 'ftol': 1e-3, 'gtol': 1e-05, 'eps': 1e-08, 'maxfun': 15000, 'maxiter': 15, 'iprint': - 1, 'maxls': 20}.

In this [file](https://github.com/meyerscetbon/lp-ci-test/blob/main/toy_examples.py) we provide some toy examples where we test our method on the dataset presented in the [paper](https://arxiv.org/pdf/2110.14868.pdf).
